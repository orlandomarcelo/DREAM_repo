{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#image analysis\n",
    "import skimage.io\n",
    "import imageio\n",
    "import alienlab.plot\n",
    "from alienlab.improcessing import normalize, grey_to_rgb, make_binary\n",
    "import alienlab.segment\n",
    "from alienlab.fo import FramesOperator\n",
    "import alienlab.io\n",
    "from scipy import optimize\n",
    "import glob\n",
    "from alienlab.regression_func import *\n",
    "import copy\n",
    "from VoltageIntensityClass import VoltageIntensity\n",
    "from tqdm import tqdm\n",
    "\n",
    "from joblib.externals.loky import set_loky_pickler\n",
    "from joblib import parallel_backend\n",
    "from joblib import Parallel, delayed\n",
    "from joblib import wrap_non_picklable_objects\n",
    "from skimage.transform import resize\n",
    "\n",
    "import tifffile as tiff\n",
    "\n",
    "#interactive widget packages\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "from tkinter.filedialog import askopenfilename, askdirectory\n",
    "\n",
    "from VoltageIntensityClass import VoltageIntensity\n",
    "\n",
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib ipympl\n",
    "import ipywidgets as wdg  # Using the ipython notebook widgets\n",
    "\n",
    "#%matplotlib inline\n",
    "\n",
    "\n",
    "def residuals(parameters,x_data,y_observed,func):\n",
    "    '''\n",
    "    Compute residuals of y_predicted - y_observed\n",
    "    where:\n",
    "    y_predicted = func(parameters,x_data)\n",
    "    '''\n",
    "    return func(parameters,x_data) - y_observed\n",
    "\n",
    "def clip(input_image, high = 95, low = 5):\n",
    "    im = copy.copy(input_image)\n",
    "    m = np.median(im)\n",
    "    im[im<np.percentile(im, low)]=np.percentile(im, low)\n",
    "    im[im>np.percentile(im, high)]=np.percentile(im, high)\n",
    "    return im\n",
    "\n",
    "def platt(parameters, xdata):\n",
    "    M = parameters[0]\n",
    "    alpha = parameters[1]\n",
    "    return M*(1- np.exp(-alpha*xdata/M))\n",
    "\n",
    "def exp_decay(parameters, xdata):\n",
    "    '''\n",
    "    Calculate an exponetial decay of the form:\n",
    "    S= a * exp(-xdata/b)\n",
    "    '''\n",
    "    A = parameters[0]\n",
    "    tau = parameters[1]\n",
    "    y0 = parameters[2]\n",
    "    return A * np.exp(-xdata/tau) + y0\n",
    "\n",
    "def modele_direct(parameters, x_data):\n",
    "    a = parameters[0]\n",
    "    b = parameters[1]\n",
    "    c = parameters[2]\n",
    "    d = parameters[3]\n",
    "    e = parameters[4]\n",
    "    return (a*x_data +b*np.sqrt(c*I**2+d*I+1)+e)/I\n",
    "\n",
    "def modele_inverse(parameters, x_data):\n",
    "    a = parameters[0]\n",
    "    b = parameters[1]\n",
    "    c = parameters[2]\n",
    "    d = parameters[3]\n",
    "    e = parameters[4]\n",
    "    f = parameters[5]\n",
    "    return a*I + b*np.sqrt(c*I**2+d*I+1) + e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#file_path = \"ENTER NAME OF THE FILE YOU DROPPED IN THE FILE SECTION HERE\"\n",
    "file_folder = askdirectory(title = 'Select an experiment folder') # pops up a window to select your file\n",
    "# uncomment this line if you use this jupyter notebook locally\n",
    "#'G:/DREAM/from_github/PAMFluo/Experiments/2021-06-24_12_12_Ek_video'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "show = True #option to output intermediary images in the segmentation process\n",
    "\n",
    "# Import video file in HQ and select ROI\n",
    "file_path = file_folder + \"/video_1.tiff\"\n",
    "direc = os.path.split(file_path)[0]\n",
    "\n",
    "# Initialize plotting tools\n",
    "g = alienlab.plot.ShowFigure()\n",
    "g.figsize = (15,7)\n",
    "g.save_folder = \"images\"\n",
    "g.date = False\n",
    "p = alienlab.plot.PlotFigure()\n",
    "p.figsize = (15,7)\n",
    "p.save_folder = \"images\"\n",
    "p.date = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Computed frames statistics in 0.334496 seconds ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ac32bcb4b1041a5a6943457be7854e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# read the stacked frame. dim = NxHxW (N images in the video, Heigt, Width)\n",
    "\n",
    "frames_full = skimage.io.imread(file_path)\n",
    "\n",
    "#frames_full = np.stack([frames_full[:,:,1]]*10, 0) \n",
    "#uncomment this line if you have a single RGB image. The [:,:,1] stands for selection of the green channel\n",
    "\n",
    "FO = FramesOperator(frames_full)\n",
    "im = normalize(FO.frames[0], 0, 1)\n",
    "im = grey_to_rgb(im)*255\n",
    "\n",
    "# CROP\n",
    "#y, x = alienlab.io.select_roi(np.uint8(im)) #select area of interest\n",
    "#FO.x = x\n",
    "#FO.y = y\n",
    "#FO.crop() #crop image\n",
    "\n",
    "start_time = time.time()\n",
    "FO.compute_stats() #compute various statistical values on the frames and the pixels\n",
    "FO.normalize(0, 1)\n",
    "print(\"--- Computed frames statistics in %04f seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "#FO.global_stats: each array has size N, number of frames and represents the stats of each frame\n",
    "#FO.frames_stats: each array has size FO.x, FO.y and is an image representing the N frames stats overlayed\n",
    "\n",
    "if show:\n",
    "    p.title = 'statistics'\n",
    "    p.xlabel = 'frame number'\n",
    "    p.ylabel = 'amplitude'\n",
    "    p.label_list = ['max', 'min', 'mean', 'std']\n",
    "    fig = p.plotting(np.asarray(FO.inds), [FO.global_stats['max'], \n",
    "                        FO.global_stats['min'], \n",
    "                        FO.global_stats['mean']])\n",
    "    p.save_name = 'frames_stats'\n",
    "    p.saving(fig)\n",
    "\n",
    "''' IMAGE SEGMENTATION '''\n",
    "\n",
    "# selection of the frames with high dynamics that will be used for the image segmentation process.\n",
    "# Let M be the highest value taken by a pixel in all the frames of the video. The frame F is kept for processing only if at\n",
    "# least one pixel in the frame F has a value above 0.8*M. \n",
    "FO.selected_inds = FO.select_frames(FO.global_stats['max'], FO.global_stats['max'].max()*0.8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd8b7facb06d485ba804f8c3faf6316c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1a5ba5388e0>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "plt.figure(figsize = (5, 5))\n",
    "FO.selected_inds = FO.select_frames(FO.global_stats['max'], FO.global_stats['max'].max()*0.98) # Select only images with high intensity to increase contrast and lower computation time\n",
    "\n",
    "\n",
    "imref = FO.frames[FO.selected_inds].sum(axis = 0)\n",
    "plt.imshow(imref, cmap = 'gray')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_image(contrast, autolevel, dist_max, dist_seg, disk_size, max_contrast, interact = True, showit = show):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    FO.selected_inds = FO.select_frames(FO.global_stats['max'], FO.global_stats['max'].max()*0.98) # Select only images with high intensity to increase contrast and lower computation time\n",
    "\n",
    "    #apply contrast filter to all frames\n",
    "    frames_contrast = FO.apply(skimage.filters.rank.enhance_contrast,  selem = skimage.morphology.disk(contrast))\n",
    "    #apply autolevel filter to all frames\n",
    "    frames_autolevel = FO.apply(skimage.filters.rank.autolevel, selem = skimage.morphology.disk(autolevel))\n",
    "    #sum the contrast images to get a reference grey-level contrast image\n",
    "    frame_contrast = np.sum(frames_contrast, axis = 0)\n",
    "    #sum the autolevel images to get a reference grey-level autolevel image\n",
    "    frame_autolevel = np.sum(frames_autolevel, axis = 0)\n",
    "    #obtain contrast mask from reference contrast image\n",
    "    mask_contrast = make_binary(frame_contrast, soft_hard = 1)\n",
    "    #otbain autolevel mask from reference autolevel image\n",
    "    mask_autolevel =  make_binary(frame_autolevel, soft_hard = 1)\n",
    "    #intersection of contrast aud autolevel masks\n",
    "    mask_intersect = mask_contrast * mask_autolevel\n",
    "    #clean the masks with a binary opening\n",
    "    mask_intersect = skimage.morphology.binary_opening(mask_intersect, selem = skimage.morphology.disk(disk_size))\n",
    "    #reference image of altitude for the watershed\n",
    "    auto_contrast = normalize(mask_intersect * frame_autolevel)\n",
    "    print(\"--- Computed binary mask in %04f seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "    g.cmap = \"inferno\"\n",
    "    if showit:\n",
    "        g.figsize = (40,15)\n",
    "        g.title_list =  'contrast', 'contrast threshold', 'mask intersect','autolevel', 'autolevel threshold','segmentation image'\n",
    "        g.col_num = 3\n",
    "        fig = g.multi([frame_contrast, mask_contrast, mask_intersect, \n",
    "                       frame_autolevel, mask_autolevel,  auto_contrast])\n",
    "        g.save_name = 'Segmentation reference'\n",
    "        g.saving(fig)\n",
    "\n",
    "    start_time = time.time()\n",
    "    ref = auto_contrast\n",
    "    mask = mask_intersect\n",
    "    #locate the local maxima\n",
    "    local_maxi = alienlab.segment.local_maxima(auto_contrast, max_contrast, g,\n",
    "                                                     ref_distance = dist_max, mask = mask, show = showit)\n",
    "    #perform watershed segmentation\n",
    "    watershed_im_mask = alienlab.segment.watershed(ref, mask, local_maxi,\n",
    "                                                         g, ref_distance = dist_seg, show = False)\n",
    "    segmented = watershed_im_mask\n",
    "    print(\"--- Computed segmentation in %04f seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "    if showit:\n",
    "        alienlab.segment.show_segmentation(FO, segmented, g)\n",
    "        \n",
    "    if interact == False:\n",
    "        return watershed_im_mask, FO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Computed binary mask in 1.527745 seconds ---\n",
      "--- Computed segmentation in 0.780458 seconds ---\n"
     ]
    }
   ],
   "source": [
    "mask, FO = segment_image(contrast = 2, autolevel = 3, dist_max = True, dist_seg=True, disk_size = 2, max_contrast = 2, interact = False, showit= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b9602f2a8bf41948343a03b10178585",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "g.cmap = \"tab20\"\n",
    "g.figsize = (8, 5)\n",
    "fig = g.multi(mask)\n",
    "L, H  = np.shape(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 1766/1766 [00:03<00:00, 581.31it/s]\n"
     ]
    }
   ],
   "source": [
    "# Collect item labels\n",
    "\n",
    "# Item time trajectories with overlaps\n",
    "# create a dictionnary with one entry for each item:\n",
    "'''\n",
    "{ '1.0': {'x_coords': np array, x coordinates in HQ}\n",
    "            'y_coords': np array,  y coordinates in HQ\n",
    "            'binned_coords': set, couples of (x,y) coordinates in binned video\n",
    "            'surface': number of pixels in the item in HQ\n",
    "            'pixel_values': array, size: (N, s) where N is number of frames and s surface\n",
    "            'mean': array, size N, mean value of the item intensity for each frame\n",
    "            'std':  array, size N, std value of the item intensity for each frame\n",
    "            'remains' : True, the item is present in this segmentation step\n",
    "            }\n",
    "'2.0': {'x_coords'...\n",
    "                }\n",
    "    }\n",
    "'''\n",
    "segmented = mask\n",
    "items = np.unique(segmented) #returns the set of values in items, corresponds to the values of the markers of local_maxima\n",
    "\n",
    "items_dict = {}\n",
    "for k in tqdm(items):\n",
    "    key = str(k)\n",
    "    items_dict[key] = {}\n",
    "    x_coords, y_coords = np.nonzero(segmented == k)\n",
    "    items_dict[key]['x_coords'] = x_coords\n",
    "    items_dict[key]['y_coords'] = y_coords\n",
    "    pixel_values = FO.frames[:,x_coords, y_coords]\n",
    "    items_dict[key]['pixel_values'] = pixel_values\n",
    "    items_dict[key]['surface'] = pixel_values.shape[1]\n",
    "    items_dict[key]['mean'] = np.mean(pixel_values, axis = 1)\n",
    "    items_dict[key]['std'] = np.std(pixel_values, axis = 1)\n",
    "    items_dict[key]['remains'] = True\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc2b8108d84d4aefa65fd486b59afd58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_sequence = {}\n",
    "video_sequence = {}\n",
    "fig, axs = plt.subplots(2, 2, figsize=(10, 8))\n",
    "for i in range(3):\n",
    "\n",
    "    file_path = glob.glob(file_folder + \"/*_ojip_curve_%d.csv\"%i)[0] # pops up a window to select your file\n",
    "    data_sequence[i] = pd.read_csv(file_path)\n",
    "    data_sequence[i].plot( x = \"time (s) o\", y = \"voltage (V) o\", ax= axs[0][i%2])\n",
    "\n",
    "    file_path = file_folder + \"/video_%d.tiff\"%i\n",
    "\n",
    "\n",
    "    video = tiff.imread(file_path)\n",
    "    video_sequence[i]=video\n",
    "    axs[1][i%2].plot(np.mean(video, axis = (1,2)))\n",
    "        \n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                         | 0/1766 [00:00<?, ?it/s]<ipython-input-116-05f1a77d40b3>:16: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  exposed = np.float(np.sum(video_sequence[2][0:5, x_coords, y_coords]))\n",
      "<ipython-input-116-05f1a77d40b3>:17: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  dark =  np.float(np.sum(video_sequence[0][0:5, x_coords, y_coords]))\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 1766/1766 [00:01<00:00, 1762.35it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77fe90663e974e79a55151522e21f557",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac92dd2bbe194b258cfcef182dd57a80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1a5c3ce3400>"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "NPQ_tot = []\n",
    "video_algae = []\n",
    "algae_list = list(items_dict.keys())\n",
    "result_npq = copy.copy(mask)*0.0\n",
    "for P in [5]:#[len(algae_list)]:#[8, 10, 12, 15, 18, 20, 25, 30, 35, 40, 60, 90, 120, 180, 200, 250, 300, 400, 500, 600, 700]:\n",
    "\n",
    "    #for algae in random.sample(algae_list, P):\n",
    "    for algae in tqdm(algae_list):\n",
    "        #if int(algae):# in ['1', '80', '400', '250']:\n",
    "            i = 0\n",
    "\n",
    "\n",
    "            x_coords =  items_dict[algae]['x_coords']\n",
    "            y_coords =  items_dict[algae]['y_coords']\n",
    "            \n",
    "            exposed = np.float(np.sum(video_sequence[2][0:5, x_coords, y_coords]))\n",
    "            dark =  np.float(np.sum(video_sequence[0][0:5, x_coords, y_coords]))\n",
    "            trace = np.mean(video_sequence[1][:, x_coords, y_coords], axis = (1))\n",
    "            npq = (dark-exposed)/exposed\n",
    "            video_algae.append(np.array(trace))\n",
    "            NPQ_tot.append(npq)\n",
    "          \n",
    "            result_npq[mask==int(float(algae))] = npq\n",
    "\n",
    "result_npq[result_npq != result_npq] = 1\n",
    "plt.figure()\n",
    "plt.imshow(result_npq)\n",
    "plt.figure()\n",
    "plt.imshow(FO.frames[FO.selected_inds].sum(axis = 0), cmap = 'gray')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1a5e869a3a0>"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.imshow(result_npq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89d924ae622e456ca3a3930d23473af2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(array([1.4944e+04, 2.5133e+04, 3.1900e+02, 6.2000e+01, 1.4600e+02,\n",
       "        2.3000e+01, 1.2000e+01, 0.0000e+00, 2.8000e+01, 7.8000e+01]),\n",
       " array([-0.82178218, -0.28960396,  0.24257426,  0.77475248,  1.30693069,\n",
       "         1.83910891,  2.37128713,  2.90346535,  3.43564356,  3.96782178,\n",
       "         4.5       ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.hist(result_npq[mask != 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8d94676514a40b1bff9e15563cd1763",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x0 = [1.1, 8, 0.1]\n",
    "def get_fit(decay, time):    \n",
    "\n",
    "    parameters_estimated = optimize.least_squares(residuals,  x0, bounds = (0,1e8),\n",
    "                                args = (time, decay, exp_decay))\n",
    "    \n",
    "    \n",
    "    return np.array(parameters_estimated.x)\n",
    "\n",
    "\n",
    "def make_fit(decay, time_array):\n",
    "    plt.figure()\n",
    "    params = get_fit(decay, time_array)\n",
    "    plt.plot(time_array, exp_decay(params, time_array), label = params[1])\n",
    "    plt.plot(time_array, decay, '.')\n",
    "    plt.legend()\n",
    "    \n",
    "start = 1\n",
    "decay = np.mean(video_sequence[1], axis = (1,2))[start:]\n",
    "time_array = np.linspace(0, len(decay), len(decay))\n",
    "\n",
    "\n",
    "#time_array = np.array(data_sequence[1][\"time (s) o\"].values)[30:-10]\n",
    "#decay = np.array(data_sequence[1][\"voltage (V) o\"].values)[30:-10]\n",
    "\n",
    "make_fit(decay, time_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_array = np.linspace(0, len(video_algae[i]), len(video_algae[i]))\n",
    "params = Parallel(n_jobs = -1 )(delayed(get_fit)(video_algae[i][start:], time_array[start:]) for i in range(len(video_algae)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adf21be4865e46cb8932e8b383c44092",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1a5ecb750d0>"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = np.array(params)\n",
    "tau = params[:,1]\n",
    "im_tau = np.copy(imref)*0\n",
    "for algae in algae_list:\n",
    "    algae = int(float(algae))\n",
    "    im_tau[mask==algae] = tau[algae]\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(im_tau)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6a9d68b8f95496bb0e0ba4d8b297001",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(array([1.607e+03, 1.000e+02, 3.700e+01, 1.000e+01, 1.000e+00, 6.000e+00,\n",
       "        0.000e+00, 4.000e+00, 0.000e+00, 1.000e+00]),\n",
       " array([9.60696608e-02, 2.57669143e+04, 5.15337326e+04, 7.73005509e+04,\n",
       "        1.03067369e+05, 1.28834187e+05, 1.54601006e+05, 1.80367824e+05,\n",
       "        2.06134642e+05, 2.31901461e+05, 2.57668279e+05]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.hist(tau)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89facd1b165f4df9be6fa06ecb5817c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35f709fe63e84442a6caff4b5a2d4e6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Textarea(value='', description='event:', placeholder='')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Create a random image\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10, 4))\n",
    "axs[0].imshow(im_tau)\n",
    "axs[0].axis('off')\n",
    "\n",
    "# Create and display textarea widget\n",
    "txt = wdg.Textarea(\n",
    "    value='',\n",
    "    placeholder='',\n",
    "    description='event:',\n",
    "    disabled=False\n",
    ")\n",
    "display(txt)\n",
    "coords = []\n",
    "\n",
    "# Define a callback function that will update the textarea\n",
    "def onclick(event):\n",
    "    global ix, iy\n",
    "    ix, iy = event.xdata, event.ydata\n",
    "    txt.value = str(event)#\"x= %d, y = %d\"%(ix, iy)\n",
    "\n",
    "    global coords\n",
    "    coords.append((ix, iy))\n",
    "    \n",
    "    algae_ind = mask[iy.astype(int), ix.astype(int)]\n",
    "    if algae_ind != 0:\n",
    "\n",
    "        decay = video_algae[algae_ind][1:]\n",
    "        time_array = np.linspace(0, len(decay), len(decay))\n",
    "\n",
    "        make_fit(decay, time_array)\n",
    "        params = get_fit(decay, time_array)\n",
    "        axs[1].plot(time_array, exp_decay(params, time_array), label = params[1])\n",
    "        axs[1].plot(time_array, decay, '.')\n",
    "        axs[1].legend()\n",
    "        plt.tight_layout()\n",
    "# Create an hard reference to the callback not to be cleared by the garbage collector\n",
    "ka = fig.canvas.mpl_connect('button_press_event', onclick)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "algae_ind = mask[286, 226]\n",
    "print(algae_ind)\n",
    "decay = video_algae[algae_ind][1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1a5ccf2e130>]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.plot(decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "#WAITTTTTTTTTTTTTTT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"G:/DREAM/from_github/PAMFluo/Figures/NPQ/imtau_semihealthy_ter_09_15.npy\", im_tau)\n",
    "np.save(\"G:/DREAM/from_github/PAMFluo/Figures/NPQ/im_semihealthy_ter_09_15.npy\", FO.frames[FO.selected_inds].sum(axis = 0))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([0])"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_sequence.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0e3787698a646a59f17abbae415f6b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G:/DREAM/from_github/PAMFluo/Experiments\\2021-09-16_15_37_qE_OJIP\n",
      "G:/DREAM/from_github/PAMFluo/Experiments\\2021-09-16_16_00_qE_OJIP\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.cm as cm\n",
    "folder_list = glob.glob(\"G:/DREAM/from_github/PAMFluo/Experiments/*qE_OJIP\")\n",
    "color = cm.tab10(np.tile(np.linspace(0, 1, 10), 50))\n",
    "data_sequence = {}\n",
    "video_sequence = {}\n",
    "fig, axs = plt.subplots(2, 2, figsize=(12, 8))\n",
    "for j, file_folder in enumerate(folder_list[5:]):\n",
    "    if j in [12, 14]:# not in [3, 4, 5]:\n",
    "        print(file_folder)\n",
    "        for i in range(0,3):\n",
    "\n",
    "            file_path = glob.glob(file_folder + \"/*_ojip_curve_%d.csv\"%i)[0] # pops up a window to select your file\n",
    "            data_sequence[i] = pd.read_csv(file_path)\n",
    "            x = data_sequence[i][\"time (s) o\"]\n",
    "            y = data_sequence[i][\"voltage (V) o\"]\n",
    "            axs[0][i%2].plot(x[:-3], y[:-3]/y.max(), label = os.path.split(file_folder)[1], color = color[j])\n",
    "            file_path = file_folder + \"/video_%d.tiff\"%i\n",
    "\n",
    "\n",
    "            video = tiff.imread(file_path)\n",
    "            video_sequence[i]=video\n",
    "            v = np.mean(video[:-1], axis = (1,2))\n",
    "            axs[1][i%2].plot(v/v.max(), color = color[j])\n",
    "axs[0][1].legend()    \n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.   , 0.   , 0.125, ..., 0.   , 0.125, 0.   ],\n",
       "        [0.   , 0.   , 0.   , ..., 0.   , 0.   , 0.   ],\n",
       "        [0.   , 0.   , 0.   , ..., 0.   , 0.   , 0.   ],\n",
       "        ...,\n",
       "        [0.   , 0.   , 0.   , ..., 0.   , 0.   , 0.   ],\n",
       "        [0.   , 0.   , 0.   , ..., 0.125, 0.   , 0.   ],\n",
       "        [0.   , 0.125, 0.   , ..., 0.   , 0.   , 0.   ]],\n",
       "\n",
       "       [[0.125, 0.   , 0.   , ..., 0.   , 0.   , 0.   ],\n",
       "        [0.   , 0.   , 0.   , ..., 0.   , 0.   , 0.   ],\n",
       "        [0.   , 0.   , 0.   , ..., 0.   , 0.   , 0.   ],\n",
       "        ...,\n",
       "        [0.   , 0.   , 0.   , ..., 0.   , 0.   , 0.   ],\n",
       "        [0.   , 0.   , 0.   , ..., 0.   , 0.   , 0.   ],\n",
       "        [0.   , 0.   , 0.   , ..., 0.   , 0.   , 0.   ]],\n",
       "\n",
       "       [[0.   , 0.   , 0.   , ..., 0.   , 0.   , 0.   ],\n",
       "        [0.   , 0.   , 0.   , ..., 0.   , 0.   , 0.125],\n",
       "        [0.   , 0.   , 0.   , ..., 0.   , 0.   , 0.   ],\n",
       "        ...,\n",
       "        [0.   , 0.   , 0.   , ..., 0.   , 0.   , 0.   ],\n",
       "        [0.   , 0.   , 0.   , ..., 0.   , 0.   , 0.   ],\n",
       "        [0.   , 0.   , 0.   , ..., 0.   , 0.   , 0.125]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.   , 0.   , 0.   , ..., 0.125, 0.   , 0.   ],\n",
       "        [0.   , 0.   , 0.   , ..., 0.   , 0.   , 0.   ],\n",
       "        [0.   , 0.   , 0.   , ..., 0.   , 0.125, 0.   ],\n",
       "        ...,\n",
       "        [0.   , 0.   , 0.   , ..., 0.   , 0.   , 0.   ],\n",
       "        [0.   , 0.   , 0.   , ..., 0.   , 0.   , 0.   ],\n",
       "        [0.   , 0.   , 0.   , ..., 0.   , 0.   , 0.   ]],\n",
       "\n",
       "       [[0.   , 0.   , 0.   , ..., 0.   , 0.   , 0.   ],\n",
       "        [0.   , 0.   , 0.   , ..., 0.   , 0.   , 0.   ],\n",
       "        [0.   , 0.   , 0.   , ..., 0.   , 0.125, 0.   ],\n",
       "        ...,\n",
       "        [0.   , 0.   , 0.   , ..., 0.   , 0.   , 0.125],\n",
       "        [0.   , 0.   , 0.   , ..., 0.   , 0.   , 0.   ],\n",
       "        [0.   , 0.   , 0.   , ..., 0.   , 0.   , 0.   ]],\n",
       "\n",
       "       [[0.   , 0.   , 0.   , ..., 0.   , 0.   , 0.   ],\n",
       "        [0.   , 0.   , 0.   , ..., 0.125, 0.   , 0.   ],\n",
       "        [0.   , 0.125, 0.   , ..., 0.   , 0.125, 0.   ],\n",
       "        ...,\n",
       "        [0.   , 0.   , 0.   , ..., 0.   , 0.   , 0.   ],\n",
       "        [0.   , 0.   , 0.   , ..., 0.   , 0.   , 0.   ],\n",
       "        [0.   , 0.   , 0.   , ..., 0.125, 0.   , 0.   ]]])"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video/video.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f3edb4b0fea482e9db68f5d2fd2f1ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x228464d61f0>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "fig, axs = plt.subplots(2, 3, figsize=(14, 7))\n",
    "\n",
    "vmin = 1\n",
    "vmax = 20\n",
    "\n",
    "healthy = np.load(\"G:/DREAM/from_github/PAMFluo/Figures/NPQ/imtau_healthy_09_15.npy\")\n",
    "axs[0][0].imshow(clip(healthy), vmin=vmin, vmax=vmax)\n",
    "healthy_base = np.load(\"G:/DREAM/from_github/PAMFluo/Figures/NPQ/im_healthy_09_15.npy\")\n",
    "axs[1][0].imshow(clip(healthy_base), cmap = \"gray\")\n",
    "\n",
    "sick = np.load(\"G:/DREAM/from_github/PAMFluo/Figures/NPQ/imtau_sick_09_15.npy\")\n",
    "axs[0][1].imshow(clip(sick), vmin=vmin, vmax=vmax)\n",
    "sick_base = np.load(\"G:/DREAM/from_github/PAMFluo/Figures/NPQ/im_sick_09_15.npy\")\n",
    "axs[1][1].imshow(clip(sick_base), cmap =\"gray\")\n",
    "\n",
    "\n",
    "sick = np.load(\"G:/DREAM/from_github/PAMFluo/Figures/NPQ/imtau_semihealthy_09_15.npy\")\n",
    "imcb = axs[0][2].imshow(clip(sick), vmin=vmin, vmax=vmax)\n",
    "sick_base = np.load(\"G:/DREAM/from_github/PAMFluo/Figures/NPQ/im_semihealthy_09_15.npy\")\n",
    "axs[1][2].imshow(clip(sick_base), cmap =\"gray\")\n",
    "\n",
    "fig.subplots_adjust(right=0.8)\n",
    "cbar_ax = fig.add_axes([0.85, 0.15, 0.05, 0.7])\n",
    "fig.colorbar(imcb, cax=cbar_ax)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-21-cf672a71c238>:1: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, axs = plt.subplots(2, 3, figsize=(14, 7))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58d848551bd248b292babaa41df9d7e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x1a5c22e2eb0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "fig, axs = plt.subplots(2, 3, figsize=(14, 7))\n",
    "\n",
    "vmin = 1\n",
    "vmax = 20\n",
    "\n",
    "healthy = np.load(\"G:/DREAM/from_github/PAMFluo/Figures/NPQ/imtau_semihealthy_09_15.npy\")\n",
    "axs[0][0].imshow(clip(healthy), vmin=vmin, vmax=vmax)\n",
    "healthy_base = np.load(\"G:/DREAM/from_github/PAMFluo/Figures/NPQ/im_semihealthy_09_15.npy\")\n",
    "axs[1][0].imshow(clip(healthy_base), cmap = \"gray\")\n",
    "\n",
    "sick = np.load(\"G:/DREAM/from_github/PAMFluo/Figures/NPQ/imtau_semihealthy_bis_09_15.npy\")\n",
    "axs[0][1].imshow(clip(sick), vmin=vmin, vmax=vmax)\n",
    "sick_base = np.load(\"G:/DREAM/from_github/PAMFluo/Figures/NPQ/im_semihealthy_bis_09_15.npy\")\n",
    "axs[1][1].imshow(clip(sick_base), cmap =\"gray\")\n",
    "\n",
    "\n",
    "sick = np.load(\"G:/DREAM/from_github/PAMFluo/Figures/NPQ/imtau_semihealthy_ter_09_15.npy\")\n",
    "imcb = axs[0][2].imshow(clip(sick), vmin=vmin, vmax=vmax)\n",
    "sick_base = np.load(\"G:/DREAM/from_github/PAMFluo/Figures/NPQ/im_semihealthy_ter_09_15.npy\")\n",
    "axs[1][2].imshow(clip(sick_base), cmap =\"gray\")\n",
    "\n",
    "fig.subplots_adjust(right=0.8)\n",
    "cbar_ax = fig.add_axes([0.85, 0.15, 0.05, 0.7])\n",
    "fig.colorbar(imcb, cax=cbar_ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

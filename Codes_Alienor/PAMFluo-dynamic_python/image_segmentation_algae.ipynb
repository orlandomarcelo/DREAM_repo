{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#image analysis\n",
    "import skimage.io\n",
    "import imageio\n",
    "import alienlab.plot\n",
    "from alienlab.improcessing import normalize, grey_to_rgb, make_binary\n",
    "import alienlab.segment\n",
    "from alienlab.fo import FramesOperator\n",
    "import alienlab.io\n",
    "from scipy import optimize\n",
    "\n",
    "from alienlab.regression_func import *\n",
    "\n",
    "#interactive widget packages\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "from tkinter.filedialog import askopenfilename, askdirectory\n",
    "\n",
    "\n",
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import video file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### USER ACTION:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Drag and drop a video file (.tif format) in the file section**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#file_path = \"ENTER NAME OF THE FILE YOU DROPPED IN THE FILE SECTION HERE\"\n",
    "file_folder = askdirectory(title = 'Select an experiment folder') # pops up a window to select your file\n",
    "# uncomment this line if you use this jupyter notebook locally\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "show = True #option to output intermediary images in the segmentation process\n",
    "\n",
    "# Import video file in HQ and select ROI\n",
    "file_path = file_folder + \"/video.tiff\"\n",
    "direc = os.path.split(file_path)[0]\n",
    "\n",
    "\n",
    "# Initialize plotting tools\n",
    "g = alienlab.plot.ShowFigure()\n",
    "g.figsize = (15,7)\n",
    "g.save_folder = \"images\"\n",
    "g.date = False\n",
    "p = alienlab.plot.PlotFigure()\n",
    "p.figsize = (15,7)\n",
    "p.save_folder = \"images\"\n",
    "p.date = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-process the video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Computed frames statistics in 0.370931 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# read the stacked frame. dim = NxHxW (N images in the video, Heigt, Width)\n",
    "\n",
    "frames_full = skimage.io.imread(file_path)\n",
    "\n",
    "#frames_full = np.stack([frames_full[:,:,1]]*10, 0) \n",
    "#uncomment this line if you have a single RGB image. The [:,:,1] stands for selection of the green channel\n",
    "\n",
    "FO = FramesOperator(frames_full)\n",
    "im = normalize(FO.frames[0], 0, 1)\n",
    "im = grey_to_rgb(im)*255\n",
    "\n",
    "# CROP\n",
    "#y, x = alienlab.io.select_roi(np.uint8(im)) #select area of interest\n",
    "#FO.x = x\n",
    "#FO.y = y\n",
    "#FO.crop() #crop image\n",
    "\n",
    "start_time = time.time()\n",
    "FO.compute_stats() #compute various statistical values on the frames and the pixels\n",
    "FO.normalize(0, 1)\n",
    "print(\"--- Computed frames statistics in %04f seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "#FO.global_stats: each array has size N, number of frames and represents the stats of each frame\n",
    "#FO.frames_stats: each array has size FO.x, FO.y and is an image representing the N frames stats overlayed\n",
    "\n",
    "if show:\n",
    "    p.title = 'statistics'\n",
    "    p.xlabel = 'frame number'\n",
    "    p.ylabel = 'amplitude'\n",
    "    p.label_list = ['max', 'min', 'mean', 'std']\n",
    "    fig = p.plotting(np.asarray(FO.inds), [FO.global_stats['max'], \n",
    "                        FO.global_stats['min'], \n",
    "                        FO.global_stats['mean']])\n",
    "    p.save_name = 'frames_stats'\n",
    "    p.saving(fig)\n",
    "\n",
    "''' IMAGE SEGMENTATION '''\n",
    "\n",
    "# selection of the frames with high dynamics that will be used for the image segmentation process.\n",
    "# Let M be the highest value taken by a pixel in all the frames of the video. The frame F is kept for processing only if at\n",
    "# least one pixel in the frame F has a value above 0.8*M. \n",
    "FO.selected_inds = FO.select_frames(FO.global_stats['max'], FO.global_stats['max'].max()*0.8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show reference image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x23c02f5c850>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "plt.figure(figsize = (5, 5))\n",
    "FO.selected_inds = FO.select_frames(FO.global_stats['max'], FO.global_stats['max'].max()*0.98) # Select only images with high intensity to increase contrast and lower computation time\n",
    "\n",
    "plt.imshow(FO.frames[FO.selected_inds].sum(axis = 0), cmap = 'gray')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_image(contrast, autolevel, dist_max, dist_seg, disk_size, max_contrast, interact = True, showit = show):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    FO.selected_inds = FO.select_frames(FO.global_stats['max'], FO.global_stats['max'].max()*0.98) # Select only images with high intensity to increase contrast and lower computation time\n",
    "\n",
    "    #apply contrast filter to all frames\n",
    "    frames_contrast = FO.apply(skimage.filters.rank.enhance_contrast,  selem = skimage.morphology.disk(contrast))\n",
    "    #apply autolevel filter to all frames\n",
    "    frames_autolevel = FO.apply(skimage.filters.rank.autolevel, selem = skimage.morphology.disk(autolevel))\n",
    "    #sum the contrast images to get a reference grey-level contrast image\n",
    "    frame_contrast = np.sum(frames_contrast, axis = 0)\n",
    "    #sum the autolevel images to get a reference grey-level autolevel image\n",
    "    frame_autolevel = np.sum(frames_autolevel, axis = 0)\n",
    "    #obtain contrast mask from reference contrast image\n",
    "    mask_contrast = make_binary(frame_contrast, soft_hard = 1)\n",
    "    #otbain autolevel mask from reference autolevel image\n",
    "    mask_autolevel =  make_binary(frame_autolevel, soft_hard = 1)\n",
    "    #intersection of contrast aud autolevel masks\n",
    "    mask_intersect = mask_contrast * mask_autolevel\n",
    "    #clean the masks with a binary opening\n",
    "    mask_intersect = skimage.morphology.binary_opening(mask_intersect, selem = skimage.morphology.disk(disk_size))\n",
    "    #reference image of altitude for the watershed\n",
    "    auto_contrast = normalize(mask_intersect * frame_autolevel)\n",
    "    print(\"--- Computed binary mask in %04f seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "    g.cmap = \"inferno\"\n",
    "    if showit:\n",
    "        g.figsize = (40,15)\n",
    "        g.title_list =  'contrast', 'contrast threshold', 'mask intersect','autolevel', 'autolevel threshold','segmentation image'\n",
    "        g.col_num = 3\n",
    "        fig = g.multi([frame_contrast, mask_contrast, mask_intersect, \n",
    "                       frame_autolevel, mask_autolevel,  auto_contrast])\n",
    "        g.save_name = 'Segmentation reference'\n",
    "        g.saving(fig)\n",
    "\n",
    "    start_time = time.time()\n",
    "    ref = auto_contrast\n",
    "    mask = mask_intersect\n",
    "    #locate the local maxima\n",
    "    local_maxi = alienlab.segment.local_maxima(auto_contrast, max_contrast, g,\n",
    "                                                     ref_distance = dist_max, mask = mask, show = showit)\n",
    "    #perform watershed segmentation\n",
    "    watershed_im_mask = alienlab.segment.watershed(ref, mask, local_maxi,\n",
    "                                                         g, ref_distance = dist_seg, show = False)\n",
    "    segmented = watershed_im_mask\n",
    "    print(\"--- Computed segmentation in %04f seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "    if showit:\n",
    "        alienlab.segment.show_segmentation(FO, segmented, g)\n",
    "        \n",
    "    if interact == False:\n",
    "        return watershed_im_mask, FO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Computed binary mask in 2.009687 seconds ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Computed segmentation in 0.742059 seconds ---\n"
     ]
    }
   ],
   "source": [
    "mask, FO = segment_image(contrast = 2, autolevel = 5, dist_max = True, dist_seg=True, disk_size = 2, max_contrast = 3, interact = False, showit= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.cmap = \"tab20\"\n",
    "fig = g.multi(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect item labels\n",
    "\n",
    "# Item time trajectories with overlaps\n",
    "# create a dictionnary with one entry for each item:\n",
    "'''\n",
    "{ '1.0': {'x_coords': np array, x coordinates in HQ}\n",
    "            'y_coords': np array,  y coordinates in HQ\n",
    "            'binned_coords': set, couples of (x,y) coordinates in binned video\n",
    "            'surface': number of pixels in the item in HQ\n",
    "            'pixel_values': array, size: (N, s) where N is number of frames and s surface\n",
    "            'mean': array, size N, mean value of the item intensity for each frame\n",
    "            'std':  array, size N, std value of the item intensity for each frame\n",
    "            'remains' : True, the item is present in this segmentation step\n",
    "            }\n",
    "'2.0': {'x_coords'...\n",
    "                }\n",
    "    }\n",
    "'''\n",
    "segmented = mask\n",
    "items = np.unique(segmented) #returns the set of values in items, corresponds to the values of the markers of local_maxima\n",
    "\n",
    "items_dict = {}\n",
    "for k in items:\n",
    "    key = str(k)\n",
    "    items_dict[key] = {}\n",
    "    x_coords, y_coords = np.nonzero(segmented == k)\n",
    "    items_dict[key]['x_coords'] = x_coords\n",
    "    items_dict[key]['y_coords'] = y_coords\n",
    "    pixel_values = FO.frames[:,x_coords, y_coords]\n",
    "    items_dict[key]['pixel_values'] = pixel_values\n",
    "    items_dict[key]['surface'] = pixel_values.shape[1]\n",
    "    items_dict[key]['mean'] = np.mean(pixel_values, axis = 1)\n",
    "    items_dict[key]['std'] = np.std(pixel_values, axis = 1)\n",
    "    items_dict[key]['remains'] = True\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'intense' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-bacd4a7e628e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloglog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mintense\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'intense' is not defined"
     ]
    }
   ],
   "source": [
    "plt.loglog(intense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = file_folder + \"/mean_intense.csv\" # pops up a window to select your file\n",
    "intense = np.genfromtxt(file_path, delimiter=',')\n",
    "file_path = file_folder + \"/mean_fluo.csv\" # pops up a window to select your file\n",
    "mean_fluo = normalize(np.genfromtxt(file_path, delimiter=','))\n",
    "file_path = file_folder + \"/mean_fluo_video.csv\" # pops up a window to select your file\n",
    "mean_fluo_video = normalize(np.genfromtxt(file_path, delimiter=','))\n",
    "intense =  np.mean(intense.reshape(-1, 6), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx = FO.frames[:,0,0].max()\n",
    "F = FO.frames/xx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x228a6214940>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.imshow(F[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (10,10))\n",
    "\n",
    "for k in items:\n",
    "    if k!= 0:\n",
    "        curve = items_dict[str(k)]['mean']\n",
    "        curve = np.mean(curve.reshape(-1, 6), axis=1)\n",
    "        #plt.scatter(eleme_intensity[20:], curve[19:])\n",
    "        plt.loglog(intense, curve/intense, '.')\n",
    "    #if k== 0:\n",
    "    #    curve = items_dict[str(k)]['mean']\n",
    "    #    curve = np.mean(FO.frames[:,0,0].reshape(-1, 6), axis=1)\n",
    "    #    #plt.scatter(eleme_intensity[20:], curve[19:])\n",
    "    #    plt.loglog(intense, curve, '-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x23c066a0490>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.loglog(intense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intensity_fluo(parameters,xdata):\n",
    "    '''\n",
    "    Calculate an exponetial decay of the form:\n",
    "    F = Qmax * exp(- alpha * xdata/Qmax)\n",
    "    '''\n",
    "    Qmax = parameters[0]\n",
    "    alpha = parameters[1]\n",
    "    return Qmax * (1-np.exp(-alpha * xdata/Qmax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from alienlab.regression_func import get_func, regression_affine\n",
    "from tkinter.filedialog import askopenfilename, askdirectory\n",
    "import glob\n",
    "from alienlab.utils import pandas_to_arrays\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from NIControl.RoutinesClass import Routines\n",
    "import sys\n",
    "from sklearn.metrics import r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from config_DAQ import *\n",
    "from ThorlabsControl.DC4100_LED import ThorlabsDC4100\n",
    "from ThorlabsControl.FW102 import FW102C\n",
    "from time import time \n",
    "\n",
    "class VoltageIntensity():\n",
    "    def __init__(self):\n",
    "        experiment_folder = \"G:/DREAM/from_github/PAMFluo/Experiments/2021-06-01_18_10_bode_diagram\"\n",
    "        #\"G:\\DREAM/from_github\\PAMFluo\\Experiments/2021-05-19_18_30_bode_diagram\"#askdirectory()\n",
    "        headers, I480 = pandas_to_arrays(glob.glob(experiment_folder + \"/*light_intensity_480.csv\")[0])\n",
    "        headers, I405 = pandas_to_arrays(glob.glob(experiment_folder + \"/*light_intensity_405.csv\")[0])\n",
    "        self.voltage = {}\n",
    "        self.voltage['blue'] = I480[1]\n",
    "        self.voltage['purple'] =  I405[1]\n",
    "        self.intensity = {}\n",
    "        self.intensity['blue'] = I480[2]\n",
    "        self.intensity['purple'] = I405[2]\n",
    "        self.DO_spectrum = pd.read_csv(\"G:/DREAM/from_github/PAMFluo/specs/DO_wheel.csv\")\n",
    "        self.detector_response = {}\n",
    "        self.detector_response[\"blue\"] = pandas_to_arrays(glob.glob(experiment_folder + \"/*Detector_response_curve_blue.csv\")[0])[1]\n",
    "        self.detector_response[\"purple\"] = pandas_to_arrays(glob.glob(experiment_folder + \"/*Detector_response_curve_purple.csv\")[0])[1]\n",
    "\n",
    "\n",
    "\n",
    "    def get_DO_val(self, LED_color, DO):\n",
    "        if LED_color == 'blue':\n",
    "            wlgh = 480\n",
    "        if LED_color == 'purple':\n",
    "            wlgh = 405\n",
    "        if DO != 0:\n",
    "            func = get_func(self.DO_spectrum['wavelength'], self.DO_spectrum[str(DO)])\n",
    "            density = func(wlgh)\n",
    "        else:\n",
    "            density = 0\n",
    "        return np.float(10**(-density))\n",
    "\n",
    "\n",
    "    def get_MPPC_voltage(self, LED_color, DO, voltage_input):\n",
    "        voltage = self.detector_response[LED_color][1]\n",
    "        MPPC_voltage = self.detector_response[LED_color][2]\n",
    "        func = get_func(voltage, MPPC_voltage, k = 1)\n",
    "        density = self.get_DO_val(LED_color, DO)\n",
    "        print(\"density:\", density)\n",
    "        return func(voltage_input)*density\n",
    "\n",
    " #   def get_intensity_voltage(self):\n",
    " #       \n",
    " #       func = get_func(intensity, voltage)\n",
    " #       include DO\n",
    "\n",
    "    def get_intensity_MPPC(self, LED_color, DO, MPPC_input):\n",
    "        density = self.get_DO_val(LED_color, DO)\n",
    "        MPPC_voltage = self.voltage[LED_color]\n",
    "        intensity = self.intensity[LED_color]\n",
    "        func = get_func(MPPC_voltage, intensity)\n",
    "        return func(MPPC_input/density)*density\n",
    "\n",
    "    def get_intensity_voltage(self, LED_color, DO, voltage_input):\n",
    "        MPPC_input = self.get_MPPC_voltage(LED_color, DO, voltage_input)\n",
    "        return self.get_intensity_MPPC(LED_color, DO, MPPC_input)\n",
    "\n",
    "\n",
    "    def assert_calibration(self, logger, filter):\n",
    "        port_DC4100 = \"COM5\"\n",
    "        port_filter_wheel = \"COM3\"\n",
    "        ctrlLED = ThorlabsDC4100(logger, port = port_DC4100)\n",
    "        ctrlLED.initialise_fluo()\n",
    "        ctrlLED.set_user_limit(LED_blue, 1000)\n",
    "        ctrlLED.set_user_limit(LED_green, 1000)\n",
    "        ctrlLED.set_user_limit(LED_purple, 1000)\n",
    "   \n",
    "\n",
    "\n",
    "        fwl = FW102C(port=port_filter_wheel)\n",
    "\n",
    "           \n",
    "\n",
    " #       send 3 intensity, given voltage, measure MPPC, check predicted voltage \n",
    "        routines = Routines()\n",
    "        routines.experiment_folder(\"Check_calibration\")\n",
    "        routines.generator_analog_channels = [\"ao0\"]\n",
    "        routines.generator_digital_channels = []\n",
    "        #480\n",
    "        offset_min = 0.25\n",
    "        offset_max =  2\n",
    "        N_points = 5\n",
    "        amplitude = 0\n",
    "        routines.excitation_frequency = 10\n",
    "        routines.num_period = 10\n",
    "        routines.points_per_period = 10000\n",
    "        routines.update_rates()\n",
    "\n",
    "        fwl.move_to_filter(filters[filter])\n",
    "        offset_range_480, val_480, fluo_range_480, full_output = routines.detector_response_routine(offset_min,\n",
    "                                                                                    offset_max, amplitude, N_points, color = 'blue')\n",
    "\n",
    "        predicted_MPPC = self.get_MPPC_voltage('blue', filter, offset_range_480)\n",
    "        r2 = r2_score(predicted_MPPC, val_480)\n",
    "        print(r2)\n",
    "        plt.figure()\n",
    "        plt.plot(predicted_MPPC, val_480)\n",
    "        if abs(r2-1) > 0.2:\n",
    "            print(\"YOU NEED TO CALIBRATE THIS SET-UP\")\n",
    "            sys.exit()\n",
    "        else:\n",
    "            print(\"CALIBRATION OK\")\n",
    "        return offset_range_480, val_480, fluo_range_480, full_output\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "density: 0.0018626565330991875\n",
      "density: 0.0018626565330991875\n",
      "density: 0.0018626565330991875\n",
      "density: 0.0018626565330991875\n",
      "density: 0.0018626565330991875\n",
      "density: 0.0018626565330991875\n",
      "density: 0.0018626565330991875\n",
      "density: 0.0018626565330991875\n",
      "density: 0.0018626565330991875\n",
      "density: 0.0018626565330991875\n",
      "density: 0.0018626565330991875\n",
      "density: 0.0018626565330991875\n",
      "density: 0.01611856195966334\n",
      "density: 0.01611856195966334\n",
      "density: 0.01611856195966334\n",
      "density: 0.01611856195966334\n",
      "density: 0.01611856195966334\n",
      "density: 0.01611856195966334\n",
      "density: 0.01611856195966334\n",
      "density: 0.01611856195966334\n",
      "density: 0.01611856195966334\n",
      "density: 0.01611856195966334\n",
      "density: 0.01611856195966334\n",
      "density: 0.01611856195966334\n",
      "density: 0.057651104622681304\n",
      "density: 0.057651104622681304\n",
      "density: 0.057651104622681304\n",
      "density: 0.057651104622681304\n",
      "density: 0.057651104622681304\n",
      "density: 0.057651104622681304\n",
      "density: 0.057651104622681304\n",
      "density: 0.057651104622681304\n",
      "density: 0.057651104622681304\n",
      "density: 0.057651104622681304\n",
      "density: 0.057651104622681304\n",
      "density: 0.057651104622681304\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "N = 18\n",
    "filters = [3,2,1]\n",
    "limits_blue_low = np.linspace(1, 45, N//(2*len(filters)))\n",
    "limits_blue_high = np.linspace(50, 250, N//(2*len(filters)))\n",
    "limits_blue = np.concatenate((limits_blue_low, limits_blue_high), axis = 0)\n",
    "\n",
    "eleme_voltage = []\n",
    "loc_intensity = []\n",
    "V = VoltageIntensity()\n",
    "for f in filters:\n",
    "    for limit_blue in limits_blue:\n",
    "        eleme_voltage.extend([V.get_MPPC_voltage('blue', f, limit_blue/100)]*6)\n",
    "        loc_intensity.extend([V.get_intensity_voltage('blue', f, limit_blue/100)]*6)\n",
    "        \n",
    "eleme_intensity = V.get_intensity_MPPC('blue', f, intense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2569302ebe0>]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x256929e4be0>]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.plot(eleme_intensity[1:], loc_intensity[:-1], '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = plt.gca()\n",
    "ax.scatter(intense[1:], eleme_intensity[:-1])\n",
    "ax.set_yscale('log')\n",
    "ax.set_xscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1a999977760>]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.loglog(intense[1:], eleme_intensity[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.loglog(eleme_intensity, mean_fluo_video[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6728439e-7b54-4573-b0ae-d8c0e149576a",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'plotly_data/traces_list.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mimageio\u001b[39;00m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mitertools\u001b[39;00m\n\u001b[1;32m---> 36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfunction_figures\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m     38\u001b[0m p \u001b[38;5;241m=\u001b[39m alienlab\u001b[38;5;241m.\u001b[39mplot\u001b[38;5;241m.\u001b[39mShowFigure()\n\u001b[0;32m     39\u001b[0m p\u001b[38;5;241m.\u001b[39mextension \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.png\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32mG:\\DREAM\\from_github\\PAMFluo\\Experiments\\FOLDER_2022_12_14_SP_check\\../FOLDER_2022_03_23_FOR_PAPER\\function_figures.py:93\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[38;5;66;03m#########################################################\u001b[39;00m\n\u001b[0;32m     90\u001b[0m data_folder \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplotly_data/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 93\u001b[0m traces_list \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_folder\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtraces_list.npy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# pulses\u001b[39;00m\n\u001b[0;32m     94\u001b[0m pulses \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(data_folder \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpulses_list.npy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     95\u001b[0m Z \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\numpy\\lib\\npyio.py:407\u001b[0m, in \u001b[0;36mload\u001b[1;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[0;32m    405\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    406\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 407\u001b[0m     fid \u001b[38;5;241m=\u001b[39m stack\u001b[38;5;241m.\u001b[39menter_context(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mos_fspath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    408\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    410\u001b[0m \u001b[38;5;66;03m# Code to distinguish from NumPy binary files and pickles.\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'plotly_data/traces_list.npy'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../FOLDER_2022_03_23_FOR_PAPER/')\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import skimage\n",
    "\n",
    "\n",
    "#image analysis\n",
    "import sys\n",
    "import os\n",
    "\n",
    "import cv2\n",
    "\n",
    "import pandas as pd\n",
    "import skimage.io\n",
    "import alienlab.plot\n",
    "from alienlab.improcessing import normalize, grey_to_rgb, make_binary\n",
    "import alienlab.segment\n",
    "from alienlab.fo import FramesOperator\n",
    "import alienlab.io\n",
    "import glob\n",
    "from alienlab.regression_func import *\n",
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from joblib import Parallel, delayed\n",
    "from joblib import wrap_non_picklable_objects\n",
    "import tqdm\n",
    "\n",
    "import imageio\n",
    "import itertools\n",
    "\n",
    "from function_figures import *\n",
    "\n",
    "p = alienlab.plot.ShowFigure()\n",
    "p.extension = \".png\"\n",
    "\n",
    "p.date = False\n",
    "p.figsize = (10,10)\n",
    "p.fonttick=17\n",
    "p.fontsize=25\n",
    "p.save_folder = \"G:/DREAM/from_github/Single_cell_paper/Figures/februaryy\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def init_image(file_path):\n",
    "    frames_full = skimage.io.imread(file_path)\n",
    "\n",
    "    #frames_full = np.stack([frames_full[:,:,1]]*10, 0) \n",
    "    #uncomment this line if you have a single RGB image. The [:,:,1] stands for selection of the green channel\n",
    "\n",
    "    FO = FramesOperator(frames_full)\n",
    "    im = normalize(FO.frames[0], 0, 1)\n",
    "    im = grey_to_rgb(im)*255\n",
    "    FO.compute_stats()\n",
    "\n",
    "    # CROP\n",
    "    #y, x = alienlab.io.select_roi(np.uint8(im)) #select area of interest\n",
    "\n",
    "    FO.x = 100, 800\n",
    "    FO.y = 100, 800\n",
    "    #FO.crop() #crop image\n",
    "    return FO\n",
    "\n",
    "\n",
    "def segment_image(FO, contrast, autolevel, dist_max, dist_seg, disk_size, max_contrast, interact = True, showit = False):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    FO.selected_inds = np.linspace(250, 2050, 91).astype(int)\n",
    "\n",
    "    \n",
    "    def make_mask(contrast, autolevel, dist_max, dist_seg, disk_size, max_contrast, soft_hard_contrast, soft_hard_autolevel):\n",
    "        #apply contrast filter to all frames\n",
    "        frames_contrast = FO.apply(skimage.filters.rank.enhance_contrast,  selem = skimage.morphology.disk(contrast))\n",
    "        #apply autolevel filter to all frames\n",
    "        frames_autolevel = FO.apply(skimage.filters.rank.autolevel, selem = skimage.morphology.disk(autolevel))\n",
    "        #sum the contrast images to get a reference grey-level contrast image\n",
    "        frame_contrast = np.sum(frames_contrast, axis = 0)\n",
    "        #sum the autolevel images to get a reference grey-level autolevel image\n",
    "        frame_autolevel = np.sum(frames_autolevel, axis = 0)\n",
    "        #obtain contrast mask from reference contrast image\n",
    "        mask_contrast = make_binary(frame_contrast, soft_hard = soft_hard_contrast)\n",
    "        #otbain autolevel mask from reference autolevel image\n",
    "        mask_autolevel =  make_binary(frame_autolevel, soft_hard = soft_hard_autolevel)\n",
    "        #intersection of contrast aud autolevel masks\n",
    "        mask_intersect = mask_contrast * mask_autolevel\n",
    "        #clean the masks with a binary opening\n",
    "        mask_intersect = skimage.morphology.binary_opening(mask_intersect, selem = skimage.morphology.disk(disk_size))\n",
    "        #mask_intersect = skimage.morphology.binary_erosion(mask_intersect, selem = skimage.morphology.disk(disk_size))\n",
    "\n",
    "        #reference image of altitude for the watershed\n",
    "        auto_contrast = normalize(mask_intersect * frame_autolevel)\n",
    "        print(\"--- Computed binary mask in %04f seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "        p.cmap = \"inferno\"\n",
    "        if showit:\n",
    "            p.figsize = (20,8)\n",
    "            p.title_list =  'contrast', 'contrast threshold', 'mask intersect','autolevel', 'autolevel threshold','segmentation image'\n",
    "            p.col_num = 3\n",
    "            fig = p.multi([frame_contrast, mask_contrast, mask_intersect, \n",
    "                           frame_autolevel, mask_autolevel,  auto_contrast])\n",
    "            p.save_name = 'Segmentation reference'\n",
    "            p.saving(fig)\n",
    "            \n",
    "        return auto_contrast, mask_intersect\n",
    "    auto_contrast, mask_intersect = make_mask(contrast, autolevel, dist_max, dist_seg, disk_size, max_contrast, soft_hard_contrast = 1, soft_hard_autolevel = 1)\n",
    "    ref, mask = make_mask(contrast, autolevel, dist_max, dist_seg, disk_size, max_contrast, soft_hard_contrast = 0.3, soft_hard_autolevel = 0.5)\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    #locate the local maxima\n",
    "    local_maxi = alienlab.segment.local_maxima(auto_contrast, max_contrast, p,\n",
    "                                                     ref_distance = dist_max, mask = mask_intersect, show = showit)\n",
    "    #perform watershed segmentation\n",
    "    watershed_im_mask = alienlab.segment.watershed(ref*mask_intersect, mask , local_maxi,\n",
    "                                                         p, ref_distance = dist_seg, show = True)\n",
    "    segmented = watershed_im_mask\n",
    "    print(\"--- Computed segmentation in %04f seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "    if showit:\n",
    "        alienlab.segment.show_segmentation(FO, segmented, p)\n",
    "        \n",
    "    if interact == False:\n",
    "       return watershed_im_mask, FO    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b21b09c-ec02-4228-988b-92adf2d4d35f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3460138e-7772-4180-b206-864a5158b07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_y = []\n",
    "\n",
    "for folder in glob.glob(\"*qE_calib*\"):\n",
    "    file = glob.glob(folder + \"/video.tiff\")[0]\n",
    "    video = skimage.io.imread(file)\n",
    "    mask = video[250]>40\n",
    "    #plt.imshow(mask)\n",
    "    y = np.mean(video.reshape(video.shape[0], -1)[:,mask.flatten()], axis = (1))\n",
    "    list_y.append(y)\n",
    "    plt.plot(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b993f396-89fe-41da-a504-32911aeb89f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, y in enumerate(list_y):\n",
    "    label =  glob.glob(\"*qE_calib*\")[i]\n",
    "    if 'WT222' not in label:\n",
    "        #plt.figure()\n",
    "        plt.plot(y[y>10]/y[250], \"k\", label = label )\n",
    "        #plt.legend()\n",
    "plt.ylim(0, 1.5)\n",
    "\n",
    "plt.xlabel(\"pulse\")\n",
    "plt.ylabel(\"FM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb467c7-a3cb-4cdd-97bd-080be50f278d",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_y = []\n",
    "\"\"\"\n",
    "for folder in glob.glob(\"*qE_calib*\"):\n",
    "    file = glob.glob(folder + \"/video.tiff\")[0]\n",
    "    \n",
    "    FO = init_image(file)\n",
    "    p.save_folder= folder\n",
    "    watershed_im_mask, FO    = segment_image(FO, contrast = 6, autolevel = 5, dist_max = True, dist_seg=True, disk_size = 1, max_contrast = 3, interact = False, showit= True)  \n",
    "    np.save(folder + \"/labels.npy\", watershed_im_mask)\n",
    "    \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9ef86a7-abcf-40f6-a1f4-3c0b6f8a934f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 36/36 [00:00<00:00, 187.50it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 262/262 [00:00<00:00, 744.29it/s]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'create_ellipse' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     60\u001b[0m S_lda \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../FOLDER_2022_03_23_FOR_PAPER/plotly_data/combine4_array_S_lda.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m,  sep \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m, header \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m     62\u001b[0m x, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m---> 65\u001b[0m fig1, ax1 \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_ellipse\u001b[49m(method, [blue, orange, green], x, y, id_list, Z, lims)\n\u001b[0;32m     67\u001b[0m compare  \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j, i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m4\u001b[39m)):\n",
      "\u001b[1;31mNameError\u001b[0m: name 'create_ellipse' is not defined"
     ]
    }
   ],
   "source": [
    "list_pair2 = np.array([250, 270, 290, 1130, 1250, 1350, 1450, 1730, 2050])\n",
    "\n",
    "couples = list(itertools.combinations(list_pair2, 2))\n",
    "\n",
    "method = \"combine4\"\n",
    "\n",
    "\n",
    "@delayed\n",
    "@wrap_non_picklable_objects\n",
    "def get_ratio_from_video(start_vid, F0, F1, mask_flat):\n",
    "        video = imageio.get_reader(start_vid)\n",
    "        frame_250 = video.get_data(250)\n",
    "        frame_F0 = video.get_data(F0)\n",
    "        frame_F1 = video.get_data(F1)\n",
    "        r0  = (frame_250 - frame_F0)/frame_F0\n",
    "        r1 = (frame_250 - frame_F1)/frame_F1\n",
    "        diff = r1-r0\n",
    "        diff = np.nan_to_num(diff, neginf=0, nan=0, posinf=0) \n",
    "        return diff.flatten()[mask_flat!=0]\n",
    "    \n",
    "def transform_data(data, transform):\n",
    "    #print(data.shape, transform.shape)\n",
    "    data = (data - M_lda.T)/S_lda.T\n",
    "    XT = np.dot(data, transform.T)\n",
    "    return XT\n",
    "\n",
    "\n",
    "for folder in glob.glob(\"*qE_calib*\")[0:1]:\n",
    "\n",
    "    labels = glob.glob(folder + \"/labels.npy\")[0]\n",
    "    \n",
    "    mask = np.load(labels)\n",
    "    \n",
    "    mask_flat = mask.flatten()\n",
    "\n",
    "    transforms = []\n",
    "\n",
    "    diffs = []\n",
    "\n",
    "\n",
    "    video = glob.glob(folder + \"/video.tiff\")[0]\n",
    "    \n",
    "    diff = Parallel(n_jobs = -1 )(get_ratio_from_video(video, couple[0], couple[1], mask_flat) for couple in tqdm.tqdm(couples))\n",
    "    diff = np.array(diff)\n",
    "    diffs.append(diff)\n",
    "    diffs = np.array(diffs)\n",
    "\n",
    "    diff_labels = []\n",
    "    for label in tqdm.tqdm(np.unique(mask)):\n",
    "        s = np.sum(mask==label)\n",
    "        if label !=0 and s>5:# and s<60:\n",
    "            diff_labels.append(np.mean(diffs[:,:,mask_flat[mask_flat!=0]==label], axis = -1))\n",
    "\n",
    "    diff_labels = np.array(diff_labels)\n",
    "    diff_labels.shape\n",
    "\n",
    "\n",
    "    RTr = pd.read_csv(\"../FOLDER_2022_03_23_FOR_PAPER/plotly_data/combine4_array_RTr.csv\", sep = \" \", header = None)\n",
    "    M_lda = np.array(pd.read_csv(\"../FOLDER_2022_03_23_FOR_PAPER/plotly_data/combine4_array_M_lda.csv\",  sep = \" \", header = None))\n",
    "    S_lda = np.array(pd.read_csv(\"../FOLDER_2022_03_23_FOR_PAPER/plotly_data/combine4_array_S_lda.csv\",  sep = \" \", header = None))\n",
    "\n",
    "    x, y = 0,1\n",
    "\n",
    "\n",
    "    fig1, ax1 = create_ellipse(method, [blue, orange, green], x, y, id_list, Z, lims)\n",
    "\n",
    "    compare  = []\n",
    "    for j, i in enumerate(range(2,4)):\n",
    "        arr = diff_labels[:,i,:]\n",
    "        #u = transform_data((arr-M_lda.T)/S_lda.T, RTr)\n",
    "        u = transform_data(arr, RTr)\n",
    "\n",
    "        #u = transform_data(arr, RTr)\n",
    "        Xc, Yc =  u[:,0], u[:,1]\n",
    "        #Xc, Yc = clip_xy(u[:,x], u[:,y], 0.01, 0.99 )\n",
    "        plt.plot(Xc, Yc, \"o\", color = [\"darkorange\",\"goldenrod\"][j], alpha = 0.5)\n",
    "        compare.append(u)\n",
    "\n",
    "\n",
    "    p.save_name = 'SP_effect/compare_points_%s_%d'%(folder, index)\n",
    "    u = p.saving(fig1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4fe367f-555c-42d5-a713-e3fcb6357095",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee05d13-f373-4bc5-b6da-735e56d577bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
